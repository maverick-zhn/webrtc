Automatically generated by Mendeley Desktop 1.13.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Mckeown2008,
abstract = {This whitepaper proposes OpenFlow: a way for researchers to run experimental protocols in the networks they use every day. OpenFlow is based on an Ethernet switch, with an internal flow-table, and a standardized interface to add and remove flow entries. Our goal is to encourage networking vendors to add OpenFlow to their switch products for deployment in college campus backbones and wiring closets. We believe that OpenFlow is a pragmatic compromise: on one hand, it allows researchers to run experiments on heterogeneous switches in a uniform way at line-rate and with high port-density; while on the other hand, vendors do not need to expose the internal workings of their switches. In addition to allowing researchers to evaluate their ideas in real-world traffic settings, OpenFlow could serve as a useful campus component in proposed large-scale testbeds like GENI. Two buildings at Stanford University will soon run OpenFlow networks, using commercial Ethernet switches and routers. We will work to encourage deployment at other schools; and We encourage you to consider deploying OpenFlow in your university network too.},
author = {Mckeown, Nick and Anderson, Tom and Balakrishnan, Hari and Parulkar, Guru M and Peterson, Larry L and Rexford, Jennifer and Shenker, Scott and Turner, Jonathan S and Louis, St},
doi = {10.1145/1355734.1355746},
file = {:C$\backslash$:/Users/Maverick/Desktop/bibtex\_paper/cited\_papers/p69-v38n2n-mckeown.pdf:pdf},
isbn = {9780983628309},
issn = {01464833},
journal = {Computer Communication Review},
keywords = {ethernet switch,flow-based,virtualization},
number = {2},
pages = {69--74},
title = {{OpenFlow: enabling innovation in campus networks}},
url = {http://doi.acm.org/10.1145/1355734.1355746},
volume = {38},
year = {2008}
}
@misc{Redis,
author = {Redis},
title = {{Redis}},
url = {http://redis.io}
}
@article{Turing1937a,
author = {Turing, Alan M.},
doi = {10.1112/plms/s2-42.1.230},
file = {:C$\backslash$:/Users/Maverick/Desktop/bibtex\_paper/cited\_papers/Turing\_Paper\_1936.pdf:pdf},
journal = {Proceedings of the London Mathematical Society},
number = {1},
pages = {230--265},
title = {{On computable numbers, with an application to the Entscheidungsproblem}},
volume = {42},
year = {1937}
}
@book{GroppWilliamandLuskEwingandSkjellum1999,
address = {Cambridge, MA, USA},
author = {{Gropp, William; Lusk, Ewing; Skjellum}, Anthony},
isbn = {0-262-57132-3},
publisher = {MIT Press},
title = {{Using MPI (2Nd Ed.): Portable Parallel Programming with the Message-passing Interface}},
year = {1999}
}
@article{Yee2009,
abstract = {This paper describes the design, implementation and evaluation of Native Client, a sandbox for untrusted x86 native code. Native Client aims to give browser-based applications the computational performance of native applications without compromising safety. Native Client uses software fault isolation and a secure runtime to direct system interaction and side effects through interfaces managed by Native Client. Native Client provides operating system portability for binary code while supporting performance-oriented features generally absent from Web application programming environments, such as thread support, instruction set extensions such as SSE, and use of compiler intrinsics and hand-coded assembler. We combine these properties in an open architecture that encourages community review and 3rd-party tools.},
author = {Yee, Bennet and Sehr, David and Dardyk, Gregory and Chen, J. Bradley and Muth, Robert and Ormandy, Tavis and Okasaka, Shiki and Narula, Neha and Fullagar, Nicholas},
doi = {10.1109/SP.2009.25},
file = {:C$\backslash$:/Users/Maverick/Desktop/bibtex\_paper/cited\_papers/34913.pdf:pdf},
isbn = {9780769536330},
issn = {10816011},
journal = {Proceedings - IEEE Symposium on Security and Privacy},
pages = {79--93},
title = {{Native client: A sandbox for portable, untrusted x86 native code}},
year = {2009}
}
@article{Agten2012,
abstract = {The inclusion of third-party scripts in web pages is a com- mon practice. A recent study has shown that more than half of the Alexa top 10 000 sites include scripts from more than 5 different origins. However, such script inclusions carry risks, as the included scripts operate with the privileges of the including website. We propose JSand, a server-driven but client-side Java- Script sandboxing framework. JSand requires no browser modifications: the sandboxing framework is implemented in JavaScript and is delivered to the browser by the websites that use it. Enforcement is done entirely at the client side: JSand enforces a server-specified policy on included scripts without requiring server-side filtering or rewriting of scripts. Most importantly, JSand is complete: access to all resources is mediated by the sandbox. We describe the design and implementation of JSand, and we show that it is secure, backwards compatible, and that it performs sufficiently well.},
author = {Agten, Pieter and Acker, Steven Van and Brondsema, Yoran},
doi = {10.1145/2420950.2420952},
file = {:C$\backslash$:/Users/Maverick/Desktop/bibtex\_paper/cited\_papers/JSand-.pdf:pdf},
isbn = {9781450313124},
journal = {Acsac 2012},
keywords = {sandbox,script inclusion,security architecture,web application security,web mashups},
pages = {1--10},
title = {{JSand: Complete client-side sandboxing of third-party JavaScript without browser modifications}},
url = {https://lirias.kuleuven.be/handle/123456789/360451},
year = {2012}
}
@article{Alur1994,
abstract = {We propose timed (finite) automata to model the behavior of real-time systems over time. Our definition provides a simple, and yet powerful, way to annotate state-transition graphs with timing constraints using finitely many real-valued clocks. A timed automaton accepts timed words–infinite sequences in which a real-valued time of occurrence is associated with each symbol. We study timed automata from the perspective of formal language theory: we consider closure properties, decision problems, and subclasses. We consider both nondeterministic and deterministic transition structures, and both B\"{u}chi and Muller acceptance conditions. We show that nondeterministic timed automata are closed under union and intersection, but not under complementation, whereas deterministic timed Muller automata are closed under all Boolean operations. The main construction of the paper is an (PSPACE) algorithm for checking the emptiness of the language of a (nondeterministic) timed automaton. We also prove that the universality problem and the language inclusion problem are solvable only for the deterministic automata: both problems are undecidable ($\Pi$11-hard) in the nondeterministic case and PSPACE-complete in the deterministic case. Finally, we discuss the application of this theory to automatic verification of real-time requirements of finite-state systems.},
author = {Alur, Rajeev and Dill, David L.},
doi = {10.1016/0304-3975(94)90010-8},
file = {:C$\backslash$:/Users/Maverick/Desktop/bibtex\_paper/cited\_papers/TCS94.pdf:pdf},
isbn = {0304-3975},
issn = {03043975},
journal = {Theoretical Computer Science},
number = {2},
pages = {183--235},
title = {{A theory of timed automata}},
volume = {126},
year = {1994}
}
@misc{ChromeV8,
author = {ChromeV8},
title = {{Chrome V8 Design Elements}},
url = {https://developers.google.com/v8/design}
}
@article{Papadimitriou2008,
abstract = {Huge datasets are becoming prevalent; even as researchers, we now routinely have to work with datasets that are up to a few terabytes in size. Interesting real-world applications produce huge volumes of messy data. The mining process involves several steps, starting from pre-processing the raw data to estimating the final models. As data become more abundant, scalable and easy-to-use tools for distributed processing are also emerging. Among those, Map-Reduce has been widely embraced by both academia and industry. In database terms, Map-Reduce is a simple yet powerful execution engine, which can be complemented with other data storage and management components, as necessary. In this paper we describe our experiences and findings in applying Map-Reduce, from raw data to final models, on an important mining task. In particular, we focus on co-clustering, which has been studied in many applications such as text mining, collaborative filtering, bio-informatics, graph mining. We propose the distributed co-clustering (DisCo) framework, which introduces practical approaches for distributed data pre-processing, and co-clustering. We develop DisCo using Hadoop, an open source Map-Reduce implementation. We show that DisCo can scale well and efficiently process and analyze extremely large datasets (up to several hundreds of gigabytes) on commodity hardware.},
author = {Papadimitriou, Spiros},
doi = {10.1109/ICDM.2008.142},
file = {:C$\backslash$:/Users/Maverick/Desktop/bibtex\_paper/cited\_papers/04781146.pdf:pdf},
isbn = {9780769535029},
issn = {15504786},
journal = {Proceedings - IEEE International Conference on Data Mining, ICDM},
pages = {512--521},
title = {{DisCo: Distributed Co-clustering with Map-Reduce: A case study towards petabyte-scale end-to-end mining}},
year = {2008}
}
@article{MacWilliam2013,
abstract = {We present CrowdCL, an open-source framework for the rapid development of volunteer computing and OpenCL applications on the web. Drawing inspiration from existing GPU libraries like PyCUDA, CrowdCL provides an abstraction layer for WebCL aimed at reducing boilerplate and improving code readability. CrowdCL also provides developers with a framework to easily run computations in the background of a web page, which allows developers to distribute computations across a network of clients and aggregate results on a centralized server. We compare the performance of CrowdCL against serial imple- mentations in Javascript and Java across a variety of platforms. Our benchmark results show strong promise for the web browser as a high-performance distributed computing platform.},
author = {MacWilliam, Tommy and Cecka, Cris},
doi = {10.1109/HPEC.2013.6670348},
file = {:C$\backslash$:/Users/Maverick/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/MacWilliam, Cecka - 2013 - CrowdCL Web-based volunteer computing with WebCL.pdf:pdf},
isbn = {978-1-4799-1365-7},
journal = {2013 IEEE High Performance Extreme Computing Conference, HPEC 2013},
title = {{CrowdCL: Web-based volunteer computing with WebCL}},
year = {2013}
}
@misc{Socket.,
author = {Socket.io},
title = {{Socket.io}},
url = {http://socket.io/}
}
@article{Dabek2002,
abstract = {Events are a better means of managing I/O concurrency in server software than threads: events help avoid bugs caused by the unnecessary CPU concurrency introduced by threads. Event-based programs also tend to have more sta- ble performance under heavy load than threaded programs. We argue that our libasync non-blocking I/O library makes event-based programming convenient and evaluate exten- sions to the library that allow event-based programs to take advantage of multi-processors. We conclude that events pro- vide all the beneﬁts of threads, with substantially less com- plexity; the result is more robust software.},
author = {Dabek, Frank and Zeldovich, Nickolai},
doi = {10.1145/1133373.1133410},
file = {:C$\backslash$:/Users/Maverick/Desktop/bibtex\_paper/cited\_papers/dabek-event.pdf:pdf},
journal = {Proceedings of the 10th workshop on ACM SIGOPS European workshopn workshop},
pages = {186 -- 189},
title = {{Event-driven programming for robust software}},
url = {http://dl.acm.org/citation.cfm?id=1133410},
year = {2002}
}
@article{Chu2007,
abstract = {We are at the beginning of the multicore era. Computers will have increasingly many cores (processors), but there is still no good programming framework for these architectures, and thus no simple and unified way for machine learning to take advantage of the potential speed up. In this paper, we develop a broadly ap- plicable parallel programming method, one that is easily applied to many different learning algorithms. Our work is in distinct contrast to the tradition in machine learning of designing (often ingenious) ways to speed up a single algorithm at a time. Specifically, we show that algorithms that fit the Statistical Query model [15] can be written in a certain “summation form,” which allows them to be easily par- allelized on multicore computers. We adapt Google’s map-reduce [7] paradigm to demonstrate this parallel speed up technique on a variety of learning algorithms including locally weighted linear regression (LWLR), k-means, logistic regres- sion (LR), naive Bayes (NB), SVM, ICA, PCA, gaussian discriminant analysis (GDA), EM, and backpropagation (NN). Our experimental results show basically linear speedup with an increasing number of processors.},
author = {Chu, Cheng-Tao and Kim, Sang Kyun and Lin, Yi-An and Yu, YuanYuan and Bradski, Gary and Ng, Andrew Y. and Olukotun, Kunle},
doi = {10.1234/12345678},
file = {:C$\backslash$:/Users/Maverick/Desktop/bibtex\_paper/cited\_papers/3150-map-reduce-for-machine-learning-on-multicore.pdf:pdf},
isbn = {0262195682},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems 19},
pages = {281--288},
title = {{Map-Reduce for Machine Learning on Multicore}},
year = {2007}
}
@misc{NPM,
author = {NPM},
title = {{Node Package Manager}},
url = {https://www.npmjs.com/}
}
@article{Kopetz1989a,
abstract = {The authors describe the Maintainable Real-Time System, a
fault-tolerant distributed system for process control, developed under
the Mars project started in 1980 at the Technische Universitat Berlin.
They explore the characteristics of distributed real-time systems and
then present the Mars approach to real-time process control, its
architectural design and implementation, and one of its applications.
The authors focus on the maintainability of the Mars architecture,
describe the Mars operating system, and discuss timing analysis. The
control of a rolling mill that produces metal plates and bars is
examined},
author = {Kopetz, Hermann and Damm, Andreas and Koza, Christian and Mulazzani, Marco and Schwabl, Wolfgang and Senft, Christoph and Zainlinger, Ralph and {Tech. Univ. of Vienna Austria}, Austria},
doi = {10.1109/40.16792},
file = {:C$\backslash$:/Users/Maverick/Desktop/bibtex\_paper/cited\_papers/Distributed Fault-Tolerant.pdf:pdf},
isbn = {0272-1732},
issn = {02721732},
journal = {IEEE Micro},
number = {1},
pages = {25--40},
title = {{Distributed fault-tolerant real-time systems: The Mars approach}},
volume = {9},
year = {1989}
}
@article{Chen2012,
author = {Chen, Hsinchun and Storey, Veda C},
file = {:C$\backslash$:/Users/Maverick/Desktop/bibtex\_paper/cited\_papers/si\_chenintroduction.pdf:pdf},
keywords = {0,big data analytics,business intelligence and analytics,web 2},
number = {4},
pages = {1165--1188},
title = {{Business Inteligence and Analytics : From Big Data To Big Impact}},
volume = {36},
year = {2012}
}
@misc{Nginx,
author = {Nginx},
title = {nginx},
url = {http://nginx.org}
}
@misc{Hadoop,
author = {Hadoop},
title = {{Hadoop}},
url = {http://hadoop.apache.org}
}
@misc{Caolan,
author = {Caolan},
title = {{Async}},
url = {https://github.com/caolan/async}
}
@article{Dewald2010,
abstract = {We present ADSandbox, an analysis system for malicious websites that focusses on detecting attacks through JavaScript. Since, in contrast to Java, JavaScript does not have any built-in sandbox concept, the idea is to execute any embed- ded JavaScript within an isolated environment and log every critical action. Using heuristics on these logs, ADSandbox decides whether the site is malicious or not. In contrast to previous work, this approach combines generality with us- ability, since the system is executed directly on the client running the web browser before the web page is displayed. We show that we can achieve false positive rates close to 0\% and false negative rates below 15\% with a performance overhead of only a few seconds, what is a bit high for real time application, but supposes a great potential for future versions of our tool.},
author = {Dewald, Andreas and Holz, Thorsten and Freiling, Felix C},
doi = {10.1145/1774088.1774482},
file = {:C$\backslash$:/Users/Maverick/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dewald, Holz, Freiling - 2010 - ADSandbox Sandboxing JavaScript to fight Malicious Websites.pdf:pdf},
isbn = {9781605586380},
journal = {Proceedings of the 2010 ACM Symposium on Applied Computing SAC 10},
keywords = {Drive-by Downloads, Dynamic Analysis, Malicious So,drive-by downloads,dynamic analysis,malicious software},
pages = {1859},
title = {{ADSandbox : Sandboxing JavaScript to fight Malicious Websites}},
url = {http://portal.acm.org/citation.cfm?doid=1774088.1774482},
year = {2010}
}
@article{Korpela2001a,
abstract = {Starting in the late 1950s, researchers have been performing
progressively more sensitive searches for radio signals from
extraterrestrial civilizations, but each search has been limited by the
technologies available at the time. As radio frequency technologies have
became more efficient and computers have become faster, the searches
have grown larger and more sensitive, The SETI@home project, managed by
a group of researchers at the Space Sciences Laboratory of the
University of California, Berkeley, is the first attempt to use
large-scale distributed computing to perform a sensitive search for
radio signals from extraterrestrial civilizations},
author = {Korpela, E. and Werthimer, D. and Anderson, D. and Cobb, J. and Leboisky, M.},
doi = {10.1109/5992.895191},
file = {:C$\backslash$:/Users/Maverick/Desktop/bibtex\_paper/cited\_papers/SET at Home.pdf:pdf},
issn = {1521-9615},
journal = {Computing in Science \& Engineering},
number = {1},
pages = {78--83},
title = {{SETI@home-massively distributed computing for SETI}},
volume = {3},
year = {2001}
}
@article{Vogt2013,
abstract = {WebRTC enables web applications to establish a direct communication channel between two browsers without relaying the data through a web server. It consists of an API [1] defined by the W3C and a set of underlying protocols defined by the IETF Rtcweb Working Group [ ... $\backslash$n},
author = {Vogt, Christian and Werner, Max Jonas and Schmidt, Thomas C.},
doi = {10.1109/ICNP.2013.6733637},
file = {:C$\backslash$:/Users/Maverick/Desktop/bibtex\_paper/cited\_papers/Leveraging WebRTC for P2P.pdf:pdf},
isbn = {9781479912704},
issn = {10921648},
journal = {Proceedings - International Conference on Network Protocols, ICNP},
title = {{Leveraging WebRTC for P2P content distribution in web browsers}},
year = {2013}
}
@misc{DougCutting,
author = {Doug, Cutting},
title = {{Hadoop}},
url = {http://hadoop.apache.org/}
}
@article{Dean2008,
abstract = {MapReduce is a programming model and an associated implementation for processing and generating large datasets that is amenable to a broad variety of real-world tasks. Users specify the computation in terms of a map and a reduce function, and the underlying runtime system automatically parallelizes the computation across large-scale clusters of machines, handles machine failures, and schedules inter-machine communication to make efficient use of the network and disks. Programmers find the system easy to use: more than ten thousand distinct MapReduce programs have been implemented internally at Google over the past four years, and an average of one hundred thousand MapReduce jobs are executed on Google's clusters every day, processing a total of more than twenty petabytes of data per day.},
archivePrefix = {arXiv},
arxivId = {10.1.1.163.5292},
author = {Dean, Jeffrey and Ghemawat, Sanjay},
doi = {10.1145/1327452.1327492},
editor = {Daniel, L Purich},
eprint = {10.1.1.163.5292},
file = {:C$\backslash$:/Users/Maverick/Desktop/bibtex\_paper/cited\_papers/mapreduce-osdi04.pdf:pdf},
institution = {Google, Inc.},
isbn = {9781595936868},
issn = {00010782},
journal = {Communications of the ACM},
number = {1},
pages = {1--13},
pmid = {11687618},
publisher = {ACM},
series = {SIGMOD '07},
title = {{MapReduce : Simplified Data Processing on Large Clusters}},
url = {http://portal.acm.org/citation.cfm?id=1327492},
volume = {51},
year = {2008}
}
@article{Herhut2013a,
abstract = {JavaScript is the most popular language on the web and is a crucial component of HTML5 applications and services that run on consumer platforms ranging from desktops to phones. However, despite ample amount of hardware parallelism available to web applications on such platforms, JavaScript web applications remain predominantly sequential. Common parallel programming solutions accepted by other programming languages failed to transfer themselves to JavaScript due to differences in programming models, the additional requirements of the web and different developer expectations. In this paper we present River Trail - a parallel programming model and API for JavaScript that provides safe, portable, programmer-friendly, deterministic parallelism to JavaScript applications. River Trail allows web applications to effectively utilize multiple cores, vector instructions, and GPUs on client platforms while allowing the web developer to remain within the environment of JavaScript. We describe the implementation of the River Trail compiler and runtime and present experimental results that show the impact of River Trail on performance and scalability for a variety of realistic HTML5 applications. Our experiments show that River Trail has a dramatic positive impact on overall performance and responsiveness of computationally intense JavaScript based applications achieving up to 33.6 times speedup for kernels and up to 11.8 times speedup for realistic web applications compared to sequential JavaScript. Moreover, River Trail enables new interactive web usages that are simply not even possible with standard sequential JavaScript.},
author = {Herhut, Stephan and Hudson, Richard L. and Shpeisman, Tatiana and Sreeram, Jaswanth},
doi = {10.1145/2509136.2509516},
file = {:C$\backslash$:/Users/Maverick/Desktop/bibtex\_paper/cited\_papers/river trail paper.pdf:pdf},
isbn = {9781450323741},
issn = {0362-1340},
journal = {Proceedings of the 2013 ACM SIGPLAN international conference on Object oriented programming systems languages \& applications - OOPSLA '13},
keywords = {javascript,parallelism},
number = {10},
pages = {729--744},
title = {{River trail}},
url = {http://dl.acm.org/citation.cfm?id=2509136.2509516},
volume = {48},
year = {2013}
}
@article{Zakai2011,
abstract = {We present Emscripten, a compiler from LLVM (Low Level Virtual Machine) assembly to JavaScript. This opens up two avenues for running code written in languages other than JavaScript on the web: (1) Compile code directly into LLVMassembly, and then compile that into JavaScript using Emscripten, or (2) Compile a languages entire runtime into LLVMand then JavaScript, as in the previous approach, and then use the compiled runtime to run code written in that language. For example, the former approach can work for C and C++, while the latter can work for Python; all three examples open up new opportunities for running code on the web. Emscripten itself is written in JavaScript and is avail- able under the MIT license (a permissive open source li- cense), at http://www.emscripten.org. As a compiler from LLVM to JavaScript, the challenges in designing Em- scripten are somewhat the reverse of the norm one must go from a low-level assembly into a high-level language, and recreate parts of the original high-level structure of the code that were lost in the compilation to low-level LLVM. We detail the methods used in Emscripten to deal with those challenges, and in particular present and prove the validity of Emscriptens Relooper algorithm, which recreates high- level loop structures from low-level branching data.},
author = {Zakai, Alon},
doi = {10.1145/2048147.2048224},
file = {:C$\backslash$:/Users/Maverick/Desktop/bibtex\_paper/cited\_papers/Emscripten.pdf:pdf},
isbn = {978-1-4503-0942-4},
journal = {Proceedings of the ACM international conference companion on Object oriented programming systems languages and applications companion},
keywords = {decompiler,javascript,llvm},
pages = {301--312},
title = {{Emscripten: an LLVM-to-JavaScript compiler}},
url = {http://doi.acm.org/10.1145/2048147.2048224},
year = {2011}
}
@article{Ekanayake2008,
abstract = {Most scientific data analyses comprise analyzing voluminous data collected from various instruments. Efficient parallel/concurrent algorithms and frameworks are the key to meeting the scalability and performance requirements entailed in such scientific data analyses. The recently introduced MapReduce technique has gained a lot of attention from the scientific community for its applicability in large parallel data analyses. Although there are many evaluations of the MapReduce technique using large textual data collections, there have been only a few evaluations for scientific data analyses. The goals of this paper are twofold. First, we present our experience in applying the MapReduce technique for two scientific data analyses: (i) high energy physics data analyses; (ii) K-means clustering. Second, we present CGL-MapReduce, a streaming-based MapReduce implementation and compare its performance with Hadoop.},
author = {Ekanayake, Jaliya and Pallickara, Shrideep and Fox, Geoffrey},
doi = {10.1109/eScience.2008.59},
file = {:C$\backslash$:/Users/Maverick/Desktop/bibtex\_paper/cited\_papers/04736768.pdf:pdf},
isbn = {9780769535357},
journal = {Proceedings - 4th IEEE International Conference on eScience, eScience 2008},
keywords = {MapReduce,Message passing,Parallel processing,Scientific data analysis},
pages = {277--284},
title = {{MapReduce for data intensive scientific analyses}},
year = {2008}
}
@article{Tilkov2010,
abstract = {One of the more interesting developments recently gaining popularity in the server-side JavaScript space is Node.js. It's a framework for developing high-performance, concurrent programs that don't rely on the mainstream multithreading approach but use asynchronous I/O with an event-driven programming model.},
author = {Tilkov, Stefan and Vinoski, Steve},
doi = {10.1109/MIC.2010.145},
file = {:C$\backslash$:/Users/Maverick/Desktop/bibtex\_paper/cited\_papers/Using JavaScript to Build High-Performance Network Programs.pdf:pdf},
isbn = {1089-7801},
issn = {10897801},
journal = {IEEE Internet Computing},
keywords = {Internet,JavaScript,Node,Node.js,Web development,functional programming},
number = {6},
pages = {80--83},
title = {{Node.js: Using JavaScript to build high-performance network programs}},
volume = {14},
year = {2010}
}
@misc{Amazon,
author = {Amazon},
title = {{Amazon Cloud Drive}},
url = {https://www.amazon.com/clouddrive/home}
}
@article{Haller2009,
abstract = {There is an impedance mismatch between message-passing concurrency and virtual machines, such as the JVM. VMs usually map their threads to heavyweight OS processes. Without a lightweight process abstraction, users are often forced to write parts of concurrent applications in an event-driven style which obscures control flow, and increases the burden on the programmer. In this paper we show how thread-based and event-based programming can be unified under a single actor abstraction. Using advanced abstraction mechanisms of the Scala programming language, we implement our approach on unmodified JVMs. Our programming model integrates well with the threading model of the underlying VM. ?? 2008 Elsevier B.V. All rights reserved.},
author = {Haller, Philipp and Odersky, Martin},
doi = {10.1016/j.tcs.2008.09.019},
file = {:C$\backslash$:/Users/Maverick/Desktop/bibtex\_paper/cited\_papers/SAUT.pdf:pdf},
isbn = {0981531601},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Actors,Concurrent programming,Events,Threads},
number = {2-3},
pages = {202--220},
publisher = {Elsevier B.V.},
title = {{Scala Actors: Unifying thread-based and event-based programming}},
url = {http://dx.doi.org/10.1016/j.tcs.2008.09.019},
volume = {410},
year = {2009}
}
